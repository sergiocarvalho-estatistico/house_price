---
title: "House Prices"
sutitle: "Preparando o conjunto de dados de treino"
author: "Sérgio Carvalho"
date: "`r format(Sys.Date(), '%d %B, %Y')`"
output:
  rmdformats::readthedown:
    self_contained: true
    thumbnails: true
    lightbox: true
    gallery: false
    highlight: zenburn 
    code_folding: show
    style_body: justify
    df_print: paged
    number_sections: yes
    toc_float:
      collapsed: yes
      smooth_scroll: yes
editor_options: 
    chunk_output_type: inline
---


```{r options-chunk, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      eval = TRUE, 
                      message = FALSE,
                      warning = FALSE, 
                      include = TRUE,
                      fig.path = "figures/",
                      fig.width = 15, 
                      fig.height = 6)
```


```{r pacotes-selecionados, message=FALSE, warning=FALSE, include=F}

  suppressMessages(library(MASS))
  suppressMessages(library(tidyverse))
  suppressMessages(library(readr))
  suppressMessages(library(dplyr))
  suppressMessages(library(data.table))
  suppressMessages(library(readxl))
  suppressMessages(library(ggplot2))
  suppressMessages(library(plotly))
  suppressMessages(library(scales))
  suppressMessages(library(lubridate))
  suppressMessages(library(reshape)) 
  suppressMessages(library(Boruta))
  suppressMessages(library(caret))
  suppressMessages(library(skimr))
  suppressMessages(library(RANN))

```

# Objetivos

  * Número de variáveis: 81 
  * Tipo de variáveis
      * * Inteiras ou discretas: 
      * * Numéricas ou double
      * * Categóricas
      * * Qualitativas
      * Qualidade dos dados          
      * * Quantidade de NA's por variável
  * Criação de novas variáveis, se precisar
  * Transformação das variáveis, se precisar


# Conjunto de Dados de Treino 

```{r read-data-train}
# Read table 
df.train <- data.table::fread('../dados/train.csv', 
                              sep=",", 
                              showProgress = FALSE) %>% 
            data.frame(stringsAsFactors = F)

df.train
```


# Há quantos tipo de dados ?

```{r metadados}
lapply(df.train,class) %>%
  unlist %>% as.character() %>% table
```


# Dados do tipo inteiro

```{r type-integer}
df.int <- df.train[,unlist(lapply(df.train,is.integer))]
df.int
```

## Resumo dos dados 

```{r resumo-dos-dados}
skim_to_wide(df.int)
```

veja que há valores nulos presente na amostra, minha estratégia será remover variáveis que possuam muitos valores nulos e imputar dados para as variáveis com poucos valores nulos.  

Primeiramente farei uma pré-seleção dos dados afim de saber se os dados que possuem valores nulos tem importância em relação a variável SalePrice.
 
 
# O Algoritmo De Boruta

  * Tenta selecionar as variáveis importantes do conjunto de dados que discriminam a variável resposta.
  * Então ele treina um classificador no conjunto de dados. 
  * Faz um rank da importância da variável com base em um score. 
  
  
```{r fig.width=15, fig.height=6}
set.seed(2510)
boruta.int <- Boruta(SalePrice ~ ., data=na.omit(df.int[,-1]), doTrace=2)  # perform Boruta search
```

```{r select-cols-int}
cols.int <- names(boruta.int$finalDecision[boruta.int$finalDecision %in% c("Confirmed", "Tentative")])  # collect
```

## Plot da importância da variável

```{r fig.width=15, fig.height=6}
plot(boruta.int, cex.axis=.7, las=2, xlab="", main="Variable Importance")
```

Selecionando as variáveis inteiras

```{r select-vars-inteiras}
df.int <- df.int[,c('Id',"SalePrice",cols.int)]
```

# Qualidade dos dados

## Tipo inteiro: % de valores nulos

```{r values-nulls, fig.width=15, fig.height=7}
apply(is.na(df.int),2,
            function(x) round(100*sum(as.numeric(x))/length(x),2)) %>% 
            sort(decreasing = T)
```

De forma geral não há muitos valores nulos no conjunto de variáveis inteiras, porém a variável LotFrontage apresenta cerca de 17.74 % de valores nulos ausentes e como há uma série de outras variáveis mais importantes que esta, decido por remove-la. 

Removendo a variável LotFrontage 

```{r remove-vars-lotfrontage}
df.int <- df.int %>% select(-LotFrontage)
```

## Imputando dados com knn

Criando um modelo com o knn para imputar dados.

```{r imput-data-with-knn-int}
preProcess_missingdata_model <- preProcess(df.int[,-c(1,2)], method='knnImpute')
preProcess_missingdata_model
```

Vamos agora usar esse modelo para prever os valores ausentes df.int

```{r}
df.int1 <- predict(preProcess_missingdata_model, newdata = df.int[,-c(1,2)] )
anyNA(df.int1)
```

Todos os valores ausentes foram imputados com sucesso, agora vamos juntar as colunas Id e SalesPrice com df.int1

```{r bind-cols-int}
df.int <- cbind(df.int[,c(1,2)],df.int1)
```

Convertento dados tipo string para tipo categórico

```{r type-str}
df.fac <- df.train[,unlist(lapply(df.train,is.character))] %>%
          apply(2,as.factor) %>% 
          data.frame()
```


## Tipo Categorical: % de valores nulos

```{r values-nulos-factor, fig.width=15, fig.height=7}
apply(is.na(df.fac),2,function(x) round(100*sum(as.numeric(x))/length(x),2)) %>% 
           sort(decreasing = T)
```

Veja que as variáveis PoolQC, MiscFeature, Alley, Fence e FireplaceQu não nos deixam outra alternativa senão a remoção delas do conjunto de dados, pois neste caso, a imputação de dados seria um grande problema na propagação do erro considerando as incertezas associadas aos métodos de imputação.

## Selecão de Variável Tipo String:

  * PoolQC
  * MiscFeature
  * Alley
  * Fence
  * FireplaceQu

  
```{r select-vars-string}
df.fac <- df.fac %>% 
            select(-PoolQC,-MiscFeature,
                   -Alley,-Fence,-FireplaceQu)
df.fac
```


## Pré-Seleção das Variáveis Categóricas

Novamente utilizarei o boruta para realizar uma pré-seleção das variáveis

```{r fig.width=15, fig.height=6}
set.seed(2510)
boruta_fac <- Boruta(SalePrice ~ ., data=na.omit(data.frame(SalePrice = df.int[,'SalePrice'],df.fac)), doTrace=2)  
# perform Boruta search
```

atribuindo a cols.fac o nome das variáveis selecionadas.

```{r name-sols-select-fac}
cols.fac <- names(boruta_fac$finalDecision[boruta_fac$finalDecision %in% c("Confirmed", "Tentative")])  
```

## Plot da importância da variável

```{r fig.width=15, fig.height=6}
plot(boruta_fac, cex.axis=.7, las=2, xlab="", main="Variable Importance")
```

# Variáveis selecionadas df.fac 

```{r vars-select-df-fac}
df.fac <- df.fac[,cols.fac]
```


```{r values-nulos-fac, fig.width=15, fig.height=7}
apply(is.na(df.fac),2,function(x) round(100*sum(as.numeric(x))/length(x),2)) %>% 
           sort(decreasing = T)
```

Como ainda estamos com valores nulos recorremos ao caret para imputar essas categorias. 


Para construir um modelo que impute nas variáveis categóricas suas categorias faltantes vamos retirar todas as variáveis que possuem alguma porcentagem de valores nulos e deixar no data frame somente uma delas em cada modelo. 

## Criando os data frames

```{r dfgaragetype-fac}
df.GarageType <- df.fac %>%
                    select(-GarageFinish,-GarageCond,
                           -BsmtExposure,-BsmtQual,
                           -BsmtCond,-BsmtFinType1,
                           -MasVnrType,-Electrical)
```


```{r GarageFinish-fac}
df.GarageFinish <- df.fac %>% 
                      select(-GarageType,-GarageCond,
                             -BsmtExposure,-BsmtQual,
                             -BsmtCond,-BsmtFinType1,
                             -MasVnrType,-Electrical)
```


```{r GarageCond-fac}
df.GarageCond <- df.fac %>% 
                    select(-GarageType,-GarageFinish,
                           -BsmtExposure,-BsmtQual,
                           -BsmtCond,-BsmtFinType1,
                           -MasVnrType,-Electrical)
```


```{r -BsmtExposure-fac}
df.BsmtExposure <- df.fac %>% 
                      select(-GarageType,-GarageFinish,
                             -GarageCond,-BsmtQual,
                             -BsmtCond,-BsmtFinType1,
                             -MasVnrType,-Electrical)
```


```{r BsmtQual-fac}
df.BsmtQual <- df.fac %>% 
                  select(-GarageType,-GarageFinish,
                         -GarageCond,-BsmtExposure,
                         -BsmtCond,-BsmtFinType1,
                         -MasVnrType,-Electrical)
```


```{r BsmtCond-fac}
df.BsmtCond <- df.fac %>% 
                  select(-GarageType,-GarageFinish,
                         -GarageCond,-BsmtExposure,
                         -BsmtQual,-BsmtFinType1,
                         -MasVnrType,-Electrical)
```


```{r BsmtFinType1-fac}
df.BsmtFinType1 <- df.fac %>% 
                      select(-GarageType,-GarageFinish,
                             -GarageCond,-BsmtExposure,
                             -BsmtQual,-BsmtCond,
                             -MasVnrType,-Electrical)
```


```{r MasVnrType-fac}
df.MasVnrType <- df.fac %>% 
                    select(-GarageType,-GarageFinish,
                           -GarageCond,-BsmtExposure,
                           -BsmtQual,-BsmtCond,
                           -BsmtFinType1,-Electrical)
```


```{r Electrical-fac}
df.Electrical <- df.fac %>% 
                  select(-GarageType,-GarageFinish,
                         -GarageCond,-BsmtExposure,
                         -BsmtQual,-BsmtCond,
                         -BsmtFinType1,-MasVnrType)
```

criando um vetor com o nome das variáveis e uma lista com os data-frames criados.

```{r varsnames-df-list}
vars <- c('GarageType','GarageFinish',
          'GarageCond','BsmtExposure',
          'BsmtQual','BsmtCond',
          'BsmtFinType1','MasVnrType',
          'Electrical')

list.df <- list(df.GarageType,df.GarageFinish,
                df.GarageCond,df.BsmtExposure,
                df.BsmtQual,df.BsmtCond,
                df.BsmtFinType1,df.MasVnrType,
                df.Electrical)
```

A função abaixo automatiza o processo de impute das categoricas nos valores nulos de cada variável.

```{r funcao-impute-fac}
f.pred <- function(fac,df.var,rf.model,var){ 

  new.df <- df.var[is.na(df.var[,var]),!(names(df.var) %in% var)]
  pred_rf <- predict(rf.model, newdata =  new.df)
  fac[is.na(fac[,var]),var] <- pred_rf

  return(fac)
}
```


## Usando a Caret e RandomForest

Utilizarei o random forest como classificador para imputar as categorias faltantes.

```{r - fitcontrol-fac}
set.seed(12345)
fitControl <- trainControl(method="cv", 
                           number=3, 
                           savePredictions = 'final',
                           classProbs= F, 
                           summaryFunction = multiClassSummary)
```

Construindos os modelos para imputar os valores nulos, para cada variável terei um modelo.


```{r rf-GarageType-fac, message=FALSE, warning=FALSE}
set.seed(12345)

# Crio uma lista para armazenar os modelos
rf.list <- list()

for(j in 1:length(vars)){ 

 # atribuo em df um df."variavel" sem os valor nulos       
 df <- list.df[[j]] %>% na.omit()  

 # treino esse df. no random-forest 
 rf.list[[j]] <- train(eval(parse(text = paste(vars[j],'~.'))),
                                      data = df, 
                                      tuneLength=5,
                                      trControl = fitControl,method='rf')

 # imputo as categorias faltantes no valores nulos das variáveis
 df.fac <- f.pred(df.fac,list.df[[j]],rf.list[[j]],vars[j])
 
 cat(j,' - ')
 
}
```

Será há algum valor nulos ?


```{r values-nulos, fig.width=15, fig.height=7}
anyNA(df.fac)
```

Imputação de dados realizada com sucesso !

# Juntandos os data frames

Jutando os dados tipo inteiros e string.

```{r bind-dfs-fac}
df.train <- bind_cols(df.int,df.fac)
```

Agora nosso df.train encontra-se limpo e pronto para ser explorado.

# Exportando os dados 

```{r output-data-objects}
write.csv(df.train,'../outputs/df.train.csv')
saveRDS(cols.int,'../outputs/cols.int.rds')
saveRDS(cols.fac,'../outputs/cols.fac.rds')
```


